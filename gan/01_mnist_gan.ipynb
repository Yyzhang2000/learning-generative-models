{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMC5lq3t7RCXEudG3VzFFTU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yyzhang2000/learning-generative-models/blob/main/gan/01_mnist_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "p9SmJf4jJ7oR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "id": "vJhqYeL2KYIq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "data_path = \"./data\"\n",
        "\n",
        "# MNIST Dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.5), std=(0.5))])\n",
        "\n",
        "train_dataset = datasets.MNIST(root=data_path, train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root=data_path, train=False, transform=transform, download=False)\n",
        "\n",
        "# Data Loader (Input Pipeline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "JBWwDlFLKcL1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9310ab85-9bff-41c3-ec94-8783512e19a2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:11<00:00, 900kB/s] \n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 65.6kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:06<00:00, 241kB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.29MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(input_dim, 256)\n",
        "        self.fc2 = nn.Linear(256, 256 * 2)\n",
        "        self.fc3 = nn.Linear(256 * 2, 256 * 4)\n",
        "        self.fc4 = nn.Linear(256 * 4, output_dim)\n",
        "\n",
        "        self.act = nn.LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act(self.fc1(x))\n",
        "        x = self.act(self.fc2(x))\n",
        "        x = self.act(self.fc3(x))\n",
        "        x = self.act(self.fc4(x))\n",
        "        return x\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(input_dim, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 1024 // 2)\n",
        "        self.fc3 = nn.Linear(1024 // 2, 1024 // 4)\n",
        "        self.fc4 = nn.Linear(1024 // 4, 1)\n",
        "\n",
        "        self.act = nn.LeakyReLU(0.2)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.dropout(self.act(self.fc1(x)))\n",
        "        x = self.dropout(self.act(self.fc2(x)))\n",
        "        x = self.dropout(self.act(self.fc3(x)))\n",
        "\n",
        "        return F.sigmoid(self.fc4(x))\n"
      ],
      "metadata": {
        "id": "Dtlf-bD4Kkie"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_dim = train_dataset.train_data.size(1) * train_dataset.train_data.size(2)\n",
        "mnist_dim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR81ehHzLxlO",
        "outputId": "e0583bc4-6fa9-4b4d-b53d-b723c9648fdf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/datasets/mnist.py:76: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "784"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z_dim = 100\n",
        "\n",
        "generator = Generator(\n",
        "    100,\n",
        "    mnist_dim\n",
        ").to(device)\n",
        "\n",
        "discriminator = Discriminator(mnist_dim).to(device)\n"
      ],
      "metadata": {
        "id": "sOUgSnz7L2o4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCELoss()\n",
        "\n",
        "lr = 1e-4\n",
        "g_optimizer = optim.Adam(generator.parameters(), lr = lr )\n",
        "d_optimizer = optim.Adam(discriminator.parameters(), lr = lr )"
      ],
      "metadata": {
        "id": "mLQaf-UNMCGP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_discrimator(model, data):\n",
        "    B = data.shape[0]\n",
        "    x_real, y_real = data.view(-1, mnist_dim), torch.ones(B, 1)\n",
        "    x_real = x_real.to(device)\n",
        "    y_real = y_real.to(device)\n",
        "\n",
        "    model_out = model(x_real)\n",
        "    model_real_loss = criterion(model_out, y_real)\n",
        "    model_real_score = model_out\n",
        "\n",
        "    # Training Discrimnator on fake image\n",
        "    z = torch.randn(B, z_dim).to(device)\n",
        "    x_fake, y_fake = generator(z), torch.zeros(B, 1).to(device)\n",
        "\n",
        "    model_out = model(x_fake)\n",
        "    model_fake_loss = criterion(model_out, y_fake)\n",
        "    model_fake_score = model_out\n",
        "\n",
        "    model_loss = model_real_loss + model_fake_loss\n",
        "    d_optimizer.zero_grad()\n",
        "    model_loss.backward()\n",
        "    d_optimizer.step()\n",
        "\n",
        "    return model_loss.item()\n"
      ],
      "metadata": {
        "id": "d6lEq-UtMcZB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_generator(model, data):\n",
        "    B = data.shape[0]\n",
        "    z = torch.randn(B, z_dim).to(device)\n",
        "    y = torch.ones(B, 1).to(device)\n",
        "\n",
        "    model_output = generator(z)\n",
        "    distrimator_output = discriminator(model_output)\n",
        "    model_loss = criterion(distrimator_output, y)\n",
        "\n",
        "    g_optimizer.zero_grad()\n",
        "    model_loss.backward()\n",
        "    g_optimizer.step()\n",
        "\n",
        "    return model_loss.item()"
      ],
      "metadata": {
        "id": "jOE1s9zqOKYs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 200\n",
        "\n",
        "def train():\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        d_losses, g_losses = [], []\n",
        "\n",
        "        for batch_idx, (x, _) in enumerate(train_loader):\n",
        "            d_loss = train_discrimator(discriminator, x)\n",
        "            g_loss = train_generator(generator, x)\n",
        "\n",
        "            d_losses.append(d_loss)\n",
        "            g_losses.append(g_loss)\n",
        "\n",
        "        print('[%d/%d]: loss_d: %.3f, loss_g: %.3f' % (\n",
        "            (epoch), n_epochs, torch.mean(torch.FloatTensor(d_losses)), torch.mean(torch.FloatTensor(g_losses))))\n"
      ],
      "metadata": {
        "id": "fLiT7qP3P2w8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train()"
      ],
      "metadata": {
        "id": "gxeKtpzuQYu_",
        "outputId": "15f4c440-2d97-4bc9-97e3-9d6fbe402647",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1/200]: loss_d: 0.687, loss_g: 1.964\n",
            "[2/200]: loss_d: 0.697, loss_g: 2.440\n",
            "[3/200]: loss_d: 0.501, loss_g: 3.622\n",
            "[4/200]: loss_d: 0.318, loss_g: 4.245\n",
            "[5/200]: loss_d: 0.216, loss_g: 4.437\n",
            "[6/200]: loss_d: 0.178, loss_g: 5.341\n",
            "[7/200]: loss_d: 0.202, loss_g: 5.333\n",
            "[8/200]: loss_d: 0.179, loss_g: 5.205\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-2da0ffaf5447>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-84102285e7b9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_discrimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-763821251373>\u001b[0m in \u001b[0;36mtrain_discrimator\u001b[0;34m(model, data)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mmodel_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_real_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel_fake_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0md_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mmodel_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0md_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.utils import save_image\n",
        "with torch.no_grad():\n",
        "    test_z = torch.randn(10, z_dim).to(device)\n",
        "    generated = generator(test_z)\n",
        "\n",
        "    save_image(generated.view(generated.size(0), 1, 28, 28), './samples/sample_' + '.png')"
      ],
      "metadata": {
        "id": "Q9xpCV92QZcb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}